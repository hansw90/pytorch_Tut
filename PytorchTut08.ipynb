{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is MNIST?\n",
    "    MNIST : handwritten digits dataset\n",
    "- Code : MNIST Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data 들어가기전에 기능알아보기\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "\"\"\"\n",
    "생략\n",
    "\"\"\"\n",
    "\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# root : MNIST 경로\n",
    "# train = True : trainset불러옴\n",
    "# train = False : testset불러옴\n",
    "# transform = transforms.ToTensor() : MNIST를 불러올떄 어떤 TRANSFORM을 적용해 가져오나?\n",
    "# download : root 에 MNIST자료가 없다면 다운을 받겠다.\n",
    "\n",
    "data_loader = torch.utils.DataLoader(DataLoader = mnist_train, batch_size, shuffle=True, drop_last=True)\n",
    "# DataLoader : 어떠한 데이터를 로드할지\n",
    "# batch_size : 몇개씩 짤라서 불러올것인지 (여기선 100개)\n",
    "# shuffle : 순서를 섞을지 순서대로 불를지\n",
    "# drop_last : 100장씩 자를때 마지막에 남는 잔챙이들 버릴까? (True : 버린다)\n",
    "\n",
    "for epoch in range(training_epochs) :\n",
    "    for X, Y in data_loader :\n",
    "        # X 는 MNIST IMG\n",
    "        # Y 는 Lable 이 옵니다.\n",
    "        \n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        # view를 이용해서 \n",
    "        # X(B,1,28,28) 사이즈의 이미지 X를 View를 이용해서 (B,784) 로 변경하여 X로 다시 저장합니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch / Batch size / Iteration\n",
    "\n",
    "__Epoch__ : 전체 데이터가 Training을 한번 끝냈을때, 1epoch    \n",
    "__batch size__ : 전체 데이터를 효율적으로 잘라 학습시키기 위함   \n",
    "__Iterations__ : batch를 몇번 학습에 사용했는가?? 1000개의 데이터를 500batch로 돌리면 2iterations을 학습에 사용했다고 합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier 를 이용하여 MNIST구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 3412218.20it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 34248.81it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1379630.22it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 13107.43it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
    "# LinearLayer의 입력 크기는 784 , \n",
    "# 출력 크기는 10 (0~9)의 숫자를 표현하기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535468519\n",
      "Epoch: 0002 cost = 0.359274179\n",
      "Epoch: 0003 cost = 0.331187516\n",
      "Epoch: 0004 cost = 0.316578031\n",
      "Epoch: 0005 cost = 0.307158172\n",
      "Epoch: 0006 cost = 0.300180703\n",
      "Epoch: 0007 cost = 0.295130193\n",
      "Epoch: 0008 cost = 0.290851504\n",
      "Epoch: 0009 cost = 0.287417084\n",
      "Epoch: 0010 cost = 0.284379542\n",
      "Epoch: 0011 cost = 0.281825215\n",
      "Epoch: 0012 cost = 0.279800713\n",
      "Epoch: 0013 cost = 0.277808994\n",
      "Epoch: 0014 cost = 0.276154310\n",
      "Epoch: 0015 cost = 0.274440885\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs): #training_epochs : 15\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader: \n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8862999677658081\n",
      "Label:  3\n",
      "Prediction:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "# grad를 계산 안하겠다\n",
    "with torch.no_grad(): \n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1) # 무작위로 이미지를 뽑는다.\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data) # 우리가 학습한 레이어에 넣어서 확인\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
